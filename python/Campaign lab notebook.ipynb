{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first-draft statistical model of London local election results\n",
    "\n",
    "The aim of the Campaign Lab event was to gather interesting sources of political data. One of the ideas floating around was to use publicly available data about wards and local authorities to say something useful about Labour's recent local election results. For example, we might identify targets by looking for areas where things have happened that correlate well with Labour vote. Working in the other direction it is also interesting to look for wards where the Labour vote was higher or lower than would be expected given the information available to the model - this can unearth otherwise hidden dynamics or potentially highlight cases where local campaigning has been particularly effective.\n",
    "\n",
    "This notebook gives a very first-draft example of the kind of model that might be useful for linking all of this data. \n",
    "\n",
    "The analysis uses [this Britain Elects spreadsheet](https://docs.google.com/spreadsheets/d/14GKPoj-E1CN0ZmiUd5gQWUi5zvGWbDoNoGT82RqKEno/edit?ts=5b07edf9#gid=0) of data about the recent local elections in London, and [this ONS data] about income levels in local authorities. The model only takes into account three facts about each ward besides its Labour vote share in 2018, namely the local authority it is in, that authority's latest available median income and its Labour vote share in the 2014 local elections. It should be fairly straightforward from a modelling point of view to extend the model to incorporate other numerical or categorical facts about wards and local authorities. \n",
    "\n",
    "### Fetching the data\n",
    "\n",
    "The first code cell imports some python libraries, fetches the data from the online spreadsheet and does a little bit of preliminary tidying.\n",
    "\n",
    "The data about election results is downloaded in the cell, whereas local authority level income data has to be downloaded manually from [here](https://beta.ons.gov.uk/filter-outputs/858e0eae-709b-4bb3-ad31-f730c73d68c1).\n",
    " \n",
    "We end up with a pandas [dataframe](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) holding facts about wards, the top of which is displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authority</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>seats</th>\n",
       "      <th>seatsCon</th>\n",
       "      <th>seatsLab</th>\n",
       "      <th>seatsLDem</th>\n",
       "      <th>seatsUKIP</th>\n",
       "      <th>seatsGrn</th>\n",
       "      <th>seatsInd</th>\n",
       "      <th>...</th>\n",
       "      <th>lastVotesOth</th>\n",
       "      <th>lastPctCon</th>\n",
       "      <th>lastPctLab</th>\n",
       "      <th>lastPctLDem</th>\n",
       "      <th>lastPctUKIP</th>\n",
       "      <th>lastPctGrn</th>\n",
       "      <th>lastPctInd</th>\n",
       "      <th>lastPctOth</th>\n",
       "      <th>authority_income_mean</th>\n",
       "      <th>authority_income_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>57.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25896.0</td>\n",
       "      <td>24593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>Alibon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>51.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25896.0</td>\n",
       "      <td>24593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>Becontree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>61.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25896.0</td>\n",
       "      <td>24593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>Chadwell Heath</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25896.0</td>\n",
       "      <td>24593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>Eastbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>222.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>25896.0</td>\n",
       "      <td>24593.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Authority            Ward  Constituency  seats  seatsCon  \\\n",
       "0  Barking & Dagenham           Abbey           NaN      3       NaN   \n",
       "1  Barking & Dagenham          Alibon           NaN      3       NaN   \n",
       "2  Barking & Dagenham       Becontree           NaN      3       NaN   \n",
       "3  Barking & Dagenham  Chadwell Heath           NaN      3       NaN   \n",
       "4  Barking & Dagenham       Eastbrook           NaN      3       NaN   \n",
       "\n",
       "   seatsLab  seatsLDem  seatsUKIP  seatsGrn  seatsInd  \\\n",
       "0       3.0        NaN        NaN       NaN       NaN   \n",
       "1       3.0        NaN        NaN       NaN       NaN   \n",
       "2       3.0        NaN        NaN       NaN       NaN   \n",
       "3       3.0        NaN        NaN       NaN       NaN   \n",
       "4       3.0        NaN        NaN       NaN       NaN   \n",
       "\n",
       "            ...             lastVotesOth  lastPctCon  lastPctLab  lastPctLDem  \\\n",
       "0           ...                     94.0        10.4        57.3          5.6   \n",
       "1           ...                      NaN         8.1        51.1          5.2   \n",
       "2           ...                      NaN         8.6        61.7          4.4   \n",
       "3           ...                      NaN        12.0        45.1          5.1   \n",
       "4           ...                    222.0        15.8        45.8          0.0   \n",
       "\n",
       "   lastPctUKIP  lastPctGrn  lastPctInd  lastPctOth  authority_income_mean  \\\n",
       "0         16.5         7.8         0.0         2.4                25896.0   \n",
       "1         35.6         0.0         0.0         0.0                25896.0   \n",
       "2         25.2         0.0         0.0         0.0                25896.0   \n",
       "3         27.7        10.2         0.0         0.0                25896.0   \n",
       "4         32.0         0.0         0.0         6.4                25896.0   \n",
       "\n",
       "   authority_income_median  \n",
       "0                  24593.0  \n",
       "1                  24593.0  \n",
       "2                  24593.0  \n",
       "3                  24593.0  \n",
       "4                  24593.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pystan\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# a matplotlib style file I put in this repo - not essential!\n",
    "plt.style.use(\"sparse.mplstyle\")\n",
    "\n",
    "# fetch data from online spreadsheet\n",
    "spreadsheet_url = (\"https://docs.google.com/spreadsheets/d/\" +\n",
    "                   \"14GKPoj-E1CN0ZmiUd5gQWUi5zvGWbDoNoGT82RqKEno/\" +\n",
    "                   \"export?&format=csv\")\n",
    "wards = pd.read_csv(spreadsheet_url, skiprows=2, na_values=['#VALUE!', '#DIV/0!'])\n",
    "\n",
    "# drop some blank columns\n",
    "to_drop = [col for col in wards.columns if 'Unnamed' in col]\n",
    "wards = wards.drop(to_drop, axis=1)\n",
    "\n",
    "# manually copied column names\n",
    "wards.columns = [\n",
    "    'Authority', 'Ward', 'Constituency', 'seats',\n",
    "    'seatsCon', 'seatsLab', 'seatsLDem', 'seatsUKIP', 'seatsGrn', 'seatsInd', 'seatsOth',\n",
    "    'lastResultCon', 'lastResultLab', 'lastResultLDem', 'lastResultUKIP', 'lastResultGrn', 'lastResultInd', 'lastResultOth',\n",
    "    'votesCon', 'votesLab', 'votesLDem', 'votesUKIP', 'votesGrn', 'votesInd', 'votesOth',\n",
    "    'pctCon', 'pctLab', 'pctLDem', 'pctUKIP', 'pctGrn', 'pctInd', 'pctOth',\n",
    "    'pctPmCon', 'pctPmLab', 'pctPmLDem', 'pctPmUKIP', 'pctPmGrn', 'pctPmInd', 'pctPmOth',\n",
    "    'lastVotesCon', 'lastVotesLab', 'lastVotesLDem', 'lastVotesUKIP', 'lastVotesGrn', 'lastVotesInd', 'lastVotesOth',\n",
    "    'lastPctCon', 'lastPctLab', 'lastPctLDem', 'lastPctUKIP', 'lastPctGrn', 'lastPctInd', 'lastPctOth'\n",
    "    \n",
    "]\n",
    "\n",
    "# load income data\n",
    "latest_income_stats = (\n",
    "    pd.read_csv(\"../data/income_data.csv\")\n",
    "    .rename(columns={'Geography': 'Authority', 'V4_2': 'income'})\n",
    "    .assign(Authority=lambda df: df['Authority'].str.replace('and ', '& '))\n",
    "    .loc[lambda df: df['income'].notnull()]\n",
    "    .groupby(['Authority', 'Statistics'])\n",
    "    .apply(lambda g: g.sort_values('Time')['income'].iloc[-1])\n",
    "    .unstack()\n",
    ")\n",
    "latest_income_stats.columns = ['authority_income_mean', 'authority_income_median']\n",
    "\n",
    "\n",
    "wards = wards.join(latest_income_stats, on='Authority')\n",
    "\n",
    "wards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell fetches in a statistical model definition in the form of a Stan program, compiles it into a Stan model object, and prints the program. This is a convenient time to go into a bit of detail about the model itself.\n",
    "\n",
    "The model is an example of linear regression: it assumes that, from ward to ward, Labour vote shares will tend to differ from a expected value in a random, normally distributed way. The expected value - `labour_vote_hat` in the code below - depends on the following model parameters (it is just their sum):\n",
    "\n",
    "- the average labour vote share for all of London (`mu`)\n",
    "- a number specific to the ward's local authority (`authority_effect`)\n",
    "- some numerical, ward-specific predictors multiplied by some regression coefficients (the predictors are `X_ward` and coefficients are `b_ward`)\n",
    "\n",
    "The amount that the model expects the observed values to vary from the expected ones is specified by another parameter `sigma_ward`.\n",
    "\n",
    "The `authority_effect` parameters have their own predictors (`X_authority`) and parameters (`b_authority` and `sigma_authority`). This makes the overall model a [multilevel model](http://www.bristol.ac.uk/cmm/learning/multilevel-models/what-why.html) - there is a level for wards and a level for local authorities. Factoring the overall variation in Labour vote shares into two components like this is nice for two reasons. First, it helps us to interpret the results - for example we can check which local authorities tended to be particularly Labour-leaning. Secondly, this form of model lines up neatly with the information that we want to take into account, which also has a multi-level structure.\n",
    "\n",
    "Together with some fairly uncontroversial prior distributions, the model defines a probability distribution which encodes what the data (along with our/its assumptions) say about all of these parameters. In order to answer statistical questions about this distribution - for example, to find out the average local authority effect for Barking & Dagenham - we need to use Markov Chain Monte Carlo to take approximate samples from it. Fortunately [Stan](http://mc-stan.org/) makes it straightforward to do this using the latest and most efficient method.\n",
    "\n",
    "Some further reading about MCMC and multilevel models:\n",
    "\n",
    " - [A really nice visualisation of Hamiltonian Monte Carlo](https://chi-feng.github.io/mcmc-demo/app.html#NaiveNUTS,banana)\n",
    " - [A paper about the history of Markov Chain Monte Carlo](https://arxiv.org/abs/1706.01520)\n",
    " - [A conceptual introduction to Hamiltonian Monte Carlo (with pictures!)](https://arxiv.org/abs/1701.02434)\n",
    " - [A very nice blog post about Hamiltonian Monte Carlo](http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/)\n",
    " - [What are multilevel models and why should I use them?](http://www.bristol.ac.uk/cmm/learning/multilevel-models/what-why.html)\n",
    " - [A case study applying multi-level modelling of baseball (and explaining why multi-level models are useful)](http://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_7cc8aa493c0e8114eb1f4bbefb377df9 NOW.\n"
     ]
    }
   ],
   "source": [
    "model = pystan.StanModel(file=\"../stan/local_election_model.stan\")\n",
    "print(model.model_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell does some pretty mundane operations on our dataframe of ward data in order to make it easy to feed into the model. \n",
    "\n",
    "The most interesting thing is that, if you add any new predictors to the `wards` dataframe, you can include them in the model just by adding their column names to either `ward_level_predictors` or `authority_level_predictors` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanify_series(s):\n",
    "    return pd.Series(s.fillna('value_missing').factorize()[0] + 1, index=s.index)\n",
    "\n",
    "def z_score(s):\n",
    "    return (s - s.mean()) / s.std()\n",
    "\n",
    "# types!\n",
    "float_cols = ['pctLab', 'lastPctLab']\n",
    "wards[float_cols] = wards[float_cols].astype(float)\n",
    "\n",
    "# nans\n",
    "wards = wards.dropna(subset=['pctLab', 'lastPctLab'])\n",
    "\n",
    "# there are some annoying duplicate names!\n",
    "wards['WardUnique'] = wards[['Authority', 'Ward']].apply('-'.join, axis=1)\n",
    "\n",
    "# factorise the categorical variables\n",
    "wards['WardStan'] = wards['WardUnique'].pipe(stanify_series)\n",
    "wards['AuthorityStan'] = wards['Authority'].pipe(stanify_series)\n",
    "\n",
    "# specify predictors\n",
    "ward_level_predictors = ['lastPctLab']\n",
    "authority_level_predictors = ['authority_income_median']\n",
    "\n",
    "# dataframe of authority-level predictors\n",
    "x_authority = wards.groupby('AuthorityStan')[authority_level_predictors].first()\n",
    "\n",
    "# define model input\n",
    "model_input = {\n",
    "    'N_ward': len(wards),\n",
    "    'N_authority': wards['Authority'].nunique(),\n",
    "    'K_ward': len(ward_level_predictors),\n",
    "    'K_authority': len(authority_level_predictors),\n",
    "    'authority': wards['AuthorityStan'],\n",
    "    'X_ward': wards[ward_level_predictors].apply(z_score),\n",
    "    'X_authority': x_authority.apply(z_score),\n",
    "    'labour_vote': wards['pctLab']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we draw samples - this should be pretty quick with our smallish dataset and few predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = 4\n",
    "n_iterations = 2000\n",
    "sample_file = '../data/samples/samples.csv'\n",
    "fit = model.sampling(data=model_input, chains=chains, iter=n_iterations, sample_file=sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some diagnostic checking, doing my best to follow the approach outlined [here](http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html). \n",
    "\n",
    "The next cell checks for [post-warmup divergent transitions](http://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html). There aren't any so that's good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_dataframe(fit, include_warmup=False):\n",
    "    first = 0 if include_warmup else fit.sim['warmup']\n",
    "    chain_dfs = [pd.DataFrame(d).iloc[first:] for d in fit.get_sampler_params()]\n",
    "    return pd.concat(chain_dfs)\n",
    "\n",
    "get_diagnostic_dataframe(fit).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract a table that summarises the posterior distributions for some parameters.\n",
    "\n",
    "First we note that the [Rhat statistics](http://www.mcmchandbook.net/HandbookChapter6.pdf) are close to one for all of the parameters shown, and the effective sample sizes are easily large enough to make sampling error practically irrelevant.\n",
    "\n",
    "Here is what the summary says about specific parameters:\n",
    "- `mu` The mean of the posterior distribution for average Labour vote share is about 45% - this is about right\n",
    "- `b_ward` This parameter represents the effect on expected 2018 Labour vote share of one stanard deviation's worth of change in 2014 share. As you would think, a higher previous Labour vote share predicts a higher 2018 share by about 15% per standard deviation.\n",
    "- `b_authority` - this parameter corresponds to the income predictor - a one standard deviation change in median income predicts about a 1.3 percentage point decrease in authority effect.\n",
    "- `sigma_ward` - this is the final error standard deviation, indicating how much the observed Labour vote shares tended to differ from the predictions. About 7% seems more or less plausible.\n",
    "- `sigma_authority` - this is the standard deviation of the authority effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_fit(fit, pars=None):\n",
    "    if pars is None:\n",
    "        pars = fit.model_pars\n",
    "    summary = fit.summary(pars=pars)\n",
    "    return pd.DataFrame(summary['summary'], \n",
    "                        columns=summary['summary_colnames'], \n",
    "                        index=summary['summary_rownames'])\n",
    "\n",
    "parameters_to_show = ['lp__', 'mu', 'b_ward', 'b_authority', 'sigma_ward', 'sigma_authority']\n",
    "\n",
    "summarise_fit(fit, pars=parameters_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the individual wards? The next cell looks at some facts about the wards that the model found most surprising, as measured by the log-scale probability of their Labour votes. These are the wards we might look at in order to discover interesting unmodelled effects.\n",
    "\n",
    "The most surprising ward is Hackney/Cazenove - its Labour vote share increased dramatically from 39% to over 90%, whereas the model's expected share was only 50%. In Newham/Stratford & New Town, the Labour share was much lower than expected at 43&, whereas the model thought it would be about 79%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authority_output = pd.DataFrame({\n",
    "    'authority_effect_mean': fit['authority_effect'].mean(axis=0),\n",
    "}, index=wards.groupby('AuthorityStan')['Authority'].first())\n",
    "\n",
    "ward_output = pd.DataFrame({\n",
    "    'labour_vote_hat_mean': fit['labour_vote_hat'].mean(axis=0),\n",
    "    'log_likelihood_mean': fit['log_likelihood'].mean(axis=0),\n",
    "    'pctLab': wards['pctLab'].values,\n",
    "    'lastPctLab': wards['lastPctLab'].values,\n",
    "    'authority_income_median': wards['authority_income_median'].values\n",
    "}, index=pd.MultiIndex.from_tuples(wards[['Authority', 'Ward']].apply(tuple, axis=1)))\n",
    "\n",
    "ward_output.index.names = ['Authority', 'Ward']\n",
    "ward_output = ward_output.join(authority_output, on='Authority')\n",
    "\n",
    "ward_output.sort_values('log_likelihood_mean').iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the overall variation, the last cell plots 2018 and 2014 Labour shares for all the wards in the Britain Elects dataset, along with the model's posterior credible intervals. Ideally, we should see about 70% of the blue dots inside the dark orange region, and 95% of them inside the lighter one, and there should be no particular pattern in the errors.\n",
    "\n",
    "This is in fact more or less what the plot shows, though there does seem to be a pattern - the dots on the left, where the model was predicting a low Labour share, seem to have generally been even lower than it thought they would be. This suggests something we might look at closer - what was special about those wards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictive_samples = pd.DataFrame(fit['labour_vote_tilde'], columns=ward_output.index)\n",
    "log_likelihood_samples = pd.DataFrame(fit['log_likelihood'], columns=ward_output.index)\n",
    "\n",
    "lower_quantile = 0.15\n",
    "upper_quantile = 0.85\n",
    "lower_quantile_2 = 0.025\n",
    "upper_quantile_2 = 0.975\n",
    "\n",
    "ppc_mean = posterior_predictive_samples.mean()\n",
    "ppc_lower = posterior_predictive_samples.quantile(lower_quantile)\n",
    "ppc_upper = posterior_predictive_samples.quantile(upper_quantile)\n",
    "ppc_lower_2 = posterior_predictive_samples.quantile(lower_quantile_2)\n",
    "ppc_upper_2 = posterior_predictive_samples.quantile(upper_quantile_2)\n",
    "\n",
    "f, ax = plt.subplots(figsize=[15, 10])\n",
    "plt.scatter(ward_output['lastPctLab'], ward_output['pctLab'], s=5, label=None, zorder=4)\n",
    "plt.vlines(ward_output['lastPctLab'], ppc_lower, ppc_upper, color='tab:orange', alpha=0.4, label='model uncertainty (70%)')\n",
    "plt.vlines(ward_output['lastPctLab'], ppc_lower_2, ppc_upper_2, color='tab:orange', alpha=0.1, label='model uncertainty (95%)')\n",
    "\n",
    "for i in log_likelihood_samples.mean().sort_values().iloc[:15].index.values:\n",
    "    plt.text(ward_output['lastPctLab'].loc[i], ward_output.loc[i, 'pctLab'], '-'.join(i), fontsize=8)\n",
    "\n",
    "\n",
    "ax.set_title(\"Where was the Labour vote higher or lower than expected?\", y=0.9, fontsize=16)\n",
    "\n",
    "plt.xlabel(\"2014 Labour vote (%)\")\n",
    "plt.ylabel(\"2018\\nLabour vote (%)\", rotation=0)\n",
    "plt.legend(frameon=False, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
